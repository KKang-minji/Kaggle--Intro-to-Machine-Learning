{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Introduction to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/model-validation).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"## Recap\nYou've built a model. In this exercise you will test how good your model is.\n\nRun the cell below to set up your coding environment where the previous exercise left off.","metadata":{}},{"cell_type":"code","source":"# Code you have previously used to load data\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Path of the file to read\niowa_file_path = '../input/home-data-for-ml-course/train.csv'\n\nhome_data = pd.read_csv(iowa_file_path)\ny = home_data.SalePrice\nfeature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\nX = home_data[feature_columns]\n\n# Specify Model\niowa_model = DecisionTreeRegressor()\n# Fit Model\niowa_model.fit(X, y)\n\nprint(\"First in-sample predictions:\", iowa_model.predict(X.head()))\nprint(\"Actual target values for those homes:\", y.head().tolist())\n\n# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.machine_learning.ex4 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-05-12T04:43:51.086909Z","iopub.execute_input":"2022-05-12T04:43:51.087183Z","iopub.status.idle":"2022-05-12T04:43:51.347593Z","shell.execute_reply.started":"2022-05-12T04:43:51.087153Z","shell.execute_reply":"2022-05-12T04:43:51.346697Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Exercises\n\n## Step 1: Split Your Data\nUse the `train_test_split` function to split up your data.\n\nGive it the argument `random_state=1` so the `check` functions know what to expect when verifying your code.\n\nRecall, your features are loaded in the DataFrame **X** and your target is loaded in **y**.\n\n\n### 1단계: 데이터 분할\ntrain_test_split 함수를 사용하여 데이터를 분할합니다.\n\nrandom_state=1 인수를 지정하면 검사 함수가 코드를 확인할 때 예상되는 사항을 알 수 있습니다.\n\n기능은 DataFrame X에 로드되고 대상은 y에 로드됩니다.\n","metadata":{}},{"cell_type":"code","source":"# Import the train_test_split function and uncomment\n# from _ import _\nfrom sklearn.model_selection import train_test_split # train 과 test 분리하는 패키지\n# fill in and uncomment\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# Check your answer\nstep_1.check()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T04:43:51.349506Z","iopub.execute_input":"2022-05-12T04:43:51.350030Z","iopub.status.idle":"2022-05-12T04:43:51.367774Z","shell.execute_reply.started":"2022-05-12T04:43:51.349980Z","shell.execute_reply":"2022-05-12T04:43:51.367052Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# The lines below will show you a hint or the solution.\n# step_1.hint() \n# step_1.solution()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T04:43:51.369421Z","iopub.execute_input":"2022-05-12T04:43:51.369696Z","iopub.status.idle":"2022-05-12T04:43:51.373235Z","shell.execute_reply.started":"2022-05-12T04:43:51.369662Z","shell.execute_reply":"2022-05-12T04:43:51.372438Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Specify and Fit the Model\n\nCreate a `DecisionTreeRegressor` model and fit it to the relevant data.\nSet `random_state` to 1 again when creating the model.\n\n### 2단계: 모델 지정 및 피팅\nDecisionTreeRegressor 모델을 만들고 관련 데이터에 맞춥니다. 모델을 생성할 때 random_state를 다시 1로 설정합니다.","metadata":{}},{"cell_type":"code","source":"# You imported DecisionTreeRegressor in your last exercise\n# and that code has been copied to the setup code above. So, no need to\n# import it again\nfrom sklearn.tree import DecisionTreeRegressor\n# Specify the model\niowa_model = DecisionTreeRegressor(random_state=1)\n\n# Fit iowa_model with the training data.\niowa_model.fit(train_X, train_y)\n\n# Check your answer\nstep_2.check()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T04:43:51.374739Z","iopub.execute_input":"2022-05-12T04:43:51.374973Z","iopub.status.idle":"2022-05-12T04:43:51.407940Z","shell.execute_reply.started":"2022-05-12T04:43:51.374944Z","shell.execute_reply":"2022-05-12T04:43:51.407020Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"데이터를 train, test로 분리한 후 해당 데이터 중 일부를 모델에 맞추기 위한 훈련(train) 데이터로 사용하고 다른 데이터를 검증 데이터로 사용하여 mean_absolute_error를 계산","metadata":{}},{"cell_type":"code","source":"# step_2.hint()\n# step_2.solution()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T04:43:51.409419Z","iopub.execute_input":"2022-05-12T04:43:51.410017Z","iopub.status.idle":"2022-05-12T04:43:51.413883Z","shell.execute_reply.started":"2022-05-12T04:43:51.409968Z","shell.execute_reply":"2022-05-12T04:43:51.413049Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Make Predictions with Validation data\n\n### 3단계: 검증 데이터로 예측하기","metadata":{}},{"cell_type":"code","source":"# Predict with all validation observations\nval_predictions = iowa_model.predict(val_X)\n\n# Check your answer\nstep_3.check()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T04:43:51.414984Z","iopub.execute_input":"2022-05-12T04:43:51.415473Z","iopub.status.idle":"2022-05-12T04:43:51.435614Z","shell.execute_reply.started":"2022-05-12T04:43:51.415434Z","shell.execute_reply":"2022-05-12T04:43:51.434735Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# step_3.hint()\n# step_3.solution()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T04:43:51.437147Z","iopub.execute_input":"2022-05-12T04:43:51.437396Z","iopub.status.idle":"2022-05-12T04:43:51.442976Z","shell.execute_reply.started":"2022-05-12T04:43:51.437363Z","shell.execute_reply":"2022-05-12T04:43:51.442157Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Inspect your predictions and actual values from validation data.","metadata":{}},{"cell_type":"code","source":"# print the top few validation predictions\nprint(____)\n# print the top few actual prices from validation data\nprint(____)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T04:43:51.444281Z","iopub.execute_input":"2022-05-12T04:43:51.444725Z","iopub.status.idle":"2022-05-12T04:43:51.455648Z","shell.execute_reply.started":"2022-05-12T04:43:51.444680Z","shell.execute_reply":"2022-05-12T04:43:51.454970Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"What do you notice that is different from what you saw with in-sample predictions (which are printed after the top code cell in this page).\n\nDo you remember why validation predictions differ from in-sample (or training) predictions? This is an important idea from the last lesson.\n\n샘플 내 예측(이 페이지의 맨 위 코드 셀 뒤에 인쇄됨)에서 본 것과 다른 점을 알 수 있습니다.\n\n검증 예측이 샘플 내(또는 훈련) 예측과 다른 이유를 기억하십니까? 이것은 지난 수업의 중요한 아이디어입니다.\n\n## Step 4: Calculate the Mean Absolute Error in Validation Data\n\n\n### 4단계: 검증 데이터의 절대 평균 오차 계산","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nval_mae = mean_absolute_error(val_y, val_predictions)\n\n# uncomment following line to see the validation_mae\n#print(val_mae)\n\n# Check your answer\nstep_4.check()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T04:43:51.456782Z","iopub.execute_input":"2022-05-12T04:43:51.456998Z","iopub.status.idle":"2022-05-12T04:43:51.478932Z","shell.execute_reply.started":"2022-05-12T04:43:51.456971Z","shell.execute_reply":"2022-05-12T04:43:51.477578Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# step_4.hint()\n# step_4.solution()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T04:43:51.481382Z","iopub.execute_input":"2022-05-12T04:43:51.482227Z","iopub.status.idle":"2022-05-12T04:43:51.488224Z","shell.execute_reply.started":"2022-05-12T04:43:51.482185Z","shell.execute_reply":"2022-05-12T04:43:51.485227Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Is that MAE good?  There isn't a general rule for what values are good that applies across applications. But you'll see how to use (and improve) this number in the next step.\n\n# Keep Going\n\nYou are ready for **[Underfitting and Overfitting](https://www.kaggle.com/dansbecker/underfitting-and-overfitting).**\n","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-machine-learning/discussion) to chat with other learners.*","metadata":{}}]}